[[upgrading-logstash]]
== Upgrading Logstash

[IMPORTANT]
===========================================
Before upgrading Logstash:

* Consult the <<breaking-changes,breaking changes>> docs.
* Test upgrades in a development environment before upgrading your production cluster.
===========================================

=== Upgrading Using Package Managers

This procedure uses <<package-repositories,package managers>> to upgrade Logstash.

1. Shut down your Logstash pipeline, including any inputs that send events to Logstash.
2. Using the directions in the _Package Repositories_ section, update your repository links to point to the 2.0 repositories
instead of the previous version.
3. Run the `apt-get upgrade logstash` or `yum update logstash` command as appropriate for your operating system.
4. Test your configuration file with the `logstash --config.test_and_exit -f <configuration-file>` command. Configuration options for
some Logstash plugins have changed in the 2.0 release.
5. Restart your Logstash pipeline after updating your configuration file.

=== Upgrading Using a Direct Download

This procedure downloads the relevant Logstash binaries directly from Elastic.

1. Shut down your Logstash pipeline, including any inputs that send events to Logstash.
2. Download the https://www.elastic.co/downloads/logstash[Logstash installation file] that matches your host environment.
3. Unpack the installation file into your Logstash directory.
4. Test your configuration file with the `logstash --config.test_and_exit -f <configuration-file>` command. Configuration options for
some Logstash plugins have changed in the 2.0 release.
5. Restart your Logstash pipeline after updating your configuration file.

[[upgrading-logstash-2.2]]
=== Upgrading Logstash to 2.2

Logstash 2.2 re-architected the pipeline stages to provide more performance and help future enhancements in resiliency.
The new pipeline introduced micro-batches, processing groups of events at a time. The default batch size is
125 per worker. Also, the filter and output stages are executed in the same thread, but still, as different stages.
The CLI flag `--pipeline-workers` or `-w` control the number of execution threads, which is set by default to number of cores.

**Considerations for Elasticsearch Output**
The default batch size of the pipeline is 125 events per worker. This will by default also be the bulk size
used for the elasticsearch output. The Elasticsearch output's `flush_size` now acts only as a maximum bulk
size (still defaulting to 500). For example, if your pipeline batch size is 3000 events, Elasticsearch
Output will send 500 events at a time, in 6 separate bulk requests. In other words, for Elasticsearch output,
bulk request size is chunked based on `flush_size` and `--pipeline.batch.size`. If `flush_size` is set greater
than `--pipeline.batch.size`, it is ignored and `--pipeline.batch.size` will be used.

The default number of output workers in Logstash 2.2 is now equal to the number of pipeline workers (`-w`)
unless overridden in the Logstash config file. This can be problematic for some users as the
extra workers may consume extra resources like file handles, especially in the case of the Elasticsearch
output. Users with more than one Elasticsearch host may want to override the `workers` setting
for the Elasticsearch output in their Logstash config to constrain that number to a low value, between 1 to 4.

**Performance Tuning in 2.2**
Since both filters and output workers are on the same thread, this could lead to threads being idle in I/O wait state.
Thus, in 2.2, you can safely set `-w` to a number which is a multiple of the number of cores on your machine.
A common way to tune performance is keep increasing the `-w` beyond the # of cores until performance no longer
improves. A note of caution - make sure you also keep heapsize in mind, because the number of in-flight events
are `#workers * batch_size * average_event size`. More in-flight events could add to memory pressure, eventually
leading to Out of Memory errors. You can change the heapsize in Logstash by setting `LS_HEAP_SIZE`.

[[upgrading-logstash-5.0]]
=== Upgrading Logstash to 5.0

Before upgrading Logstash, remember to read the <<breaking-changes,breaking changes>>.

If you are installing Logstash with other components in the Elastic Stack, also see the
{stack}index.html[Elastic Stack installation and upgrade documentation].

==== When to Upgrade

Fresh installations can and should start with the same version across the Elastic Stack. 

Elasticsearch 5.0 does not require Logstash 5.0. An Elasticsearch 5.0 cluster will happily receive data from a
Logstash 2.x instance via the default HTTP communication layer. This provides some flexibility to decide when to upgrade
Logstash relative to an Elasticsearch upgrade. It may or may not be convenient for you to upgrade them together, and it
is
not required to be done at the same time as long as Elasticsearch is upgraded first.

You should upgrade in a timely manner to get the performance improvements that come with Logstash 5.0, but do so in
the way that makes the most sense for your environment.

==== When Not to Upgrade

If any Logstash plugin that you require is not compatible with Logstash 5.0, then you should wait until it is ready
before upgrading.

Although we make great efforts to ensure compatibility, Logstash 5.0 is not completely backwards compatible. As noted
in the Elastic Stack upgrade guide, Logstash 5.0 should not be upgraded before Elasticsearch 5.0. This is both
practical and because some Logstash 5.0 plugins may attempt to use features of Elasticsearch 5.0 that did not exist
in earlier versions. For example, if you attempt to send the 5.x template to a cluster before Elasticsearch 5.0, then it
will not be able to use it and all indexing will fail likely fail. If you use your own, custom template with Logstash,
then this issue can be ignored.

Note the Elasticsearch Output Index Template change in the <<breaking-changes>> documentation for further insight into
this change and how it impacts operations.


